digraph cnn_tree {
functional_1_conv2d_Conv2D [shape=box, label="functional_1_conv2d_Conv2D\n id: 0  type: 0\n input size: 3*416*416\n output size: 16*416*416\n kernel_h: 3 kernel_w: 3\n stride_h: 1 stride_w: 1\n pad_h: 1 pad_w: 1\n pad_up: 1 pad_down 1\n pad_left: 1 pad_right 1\n report_flag: 0\n bond_type: 1\n data_bit_mode: 0\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_conv2d_Conv2D -> functional_1_batch_normalization_FusedBatchNormV3;
functional_1_batch_normalization_FusedBatchNormV3 [shape=box, label="functional_1_batch_normalization_FusedBatchNormV3\n id: 1  type: 24\n input size: 16*416*416\n output size: 16*416*416\n report_flag: 0\n bond_type: 1\n data_bit_mode: 2\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_batch_normalization_FusedBatchNormV3 -> functional_1_batch_normalization_FusedBatchNormV3_scale;
functional_1_batch_normalization_FusedBatchNormV3_scale [shape=box, label="functional_1_batch_normalization_FusedBatchNormV3_scale\n id: 2  type: 25\n input size: 16*416*416\n output size: 16*416*416\n report_flag: 0\n bond_type: 1\n data_bit_mode: 2\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_batch_normalization_FusedBatchNormV3_scale -> functional_1_max_pooling2d_MaxPool;
functional_1_max_pooling2d_MaxPool [shape=box, label="functional_1_max_pooling2d_MaxPool\n id: 3  type: 3\n input size: 16*416*416\n output size: 16*208*208\n kernel_h: 2 kernel_w: 2\n stride_h: 2 stride_w: 2\n pad_h: 0 pad_w: 0\n pad_up: 0 pad_down 0\n pad_left: 0 pad_right 0\n report_flag: 0\n bond_type: 1\n data_bit_mode: 0\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_max_pooling2d_MaxPool -> functional_1_conv2d_1_Conv2D;
functional_1_conv2d_1_Conv2D [shape=box, label="functional_1_conv2d_1_Conv2D\n id: 4  type: 0\n input size: 16*208*208\n output size: 32*208*208\n kernel_h: 3 kernel_w: 3\n stride_h: 1 stride_w: 1\n pad_h: 1 pad_w: 1\n pad_up: 1 pad_down 1\n pad_left: 1 pad_right 1\n report_flag: 0\n bond_type: 4\n data_bit_mode: 0\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_conv2d_1_Conv2D -> functional_1_batch_normalization_1_FusedBatchNormV3;
functional_1_batch_normalization_1_FusedBatchNormV3 [shape=box, label="functional_1_batch_normalization_1_FusedBatchNormV3\n id: 5  type: 24\n input size: 32*208*208\n output size: 32*208*208\n report_flag: 0\n bond_type: 1\n data_bit_mode: 2\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_batch_normalization_1_FusedBatchNormV3 -> functional_1_batch_normalization_1_FusedBatchNormV3_scale;
functional_1_batch_normalization_1_FusedBatchNormV3_scale [shape=box, label="functional_1_batch_normalization_1_FusedBatchNormV3_scale\n id: 6  type: 25\n input size: 32*208*208\n output size: 32*208*208\n report_flag: 0\n bond_type: 1\n data_bit_mode: 2\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_batch_normalization_1_FusedBatchNormV3_scale -> functional_1_max_pooling2d_1_MaxPool;
functional_1_max_pooling2d_1_MaxPool [shape=box, label="functional_1_max_pooling2d_1_MaxPool\n id: 7  type: 3\n input size: 32*208*208\n output size: 32*104*104\n kernel_h: 2 kernel_w: 2\n stride_h: 2 stride_w: 2\n pad_h: 0 pad_w: 0\n pad_up: 0 pad_down 0\n pad_left: 0 pad_right 0\n report_flag: 0\n bond_type: 1\n data_bit_mode: 0\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_max_pooling2d_1_MaxPool -> functional_1_conv2d_2_Conv2D;
functional_1_conv2d_2_Conv2D [shape=box, label="functional_1_conv2d_2_Conv2D\n id: 8  type: 0\n input size: 32*104*104\n output size: 64*104*104\n kernel_h: 3 kernel_w: 3\n stride_h: 1 stride_w: 1\n pad_h: 1 pad_w: 1\n pad_up: 1 pad_down 1\n pad_left: 1 pad_right 1\n report_flag: 0\n bond_type: 4\n data_bit_mode: 0\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_conv2d_2_Conv2D -> functional_1_batch_normalization_2_FusedBatchNormV3;
functional_1_batch_normalization_2_FusedBatchNormV3 [shape=box, label="functional_1_batch_normalization_2_FusedBatchNormV3\n id: 9  type: 24\n input size: 64*104*104\n output size: 64*104*104\n report_flag: 0\n bond_type: 1\n data_bit_mode: 2\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_batch_normalization_2_FusedBatchNormV3 -> functional_1_batch_normalization_2_FusedBatchNormV3_scale;
functional_1_batch_normalization_2_FusedBatchNormV3_scale [shape=box, label="functional_1_batch_normalization_2_FusedBatchNormV3_scale\n id: 10  type: 25\n input size: 64*104*104\n output size: 64*104*104\n report_flag: 0\n bond_type: 1\n data_bit_mode: 2\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_batch_normalization_2_FusedBatchNormV3_scale -> functional_1_max_pooling2d_2_MaxPool;
functional_1_max_pooling2d_2_MaxPool [shape=box, label="functional_1_max_pooling2d_2_MaxPool\n id: 11  type: 3\n input size: 64*104*104\n output size: 64*52*52\n kernel_h: 2 kernel_w: 2\n stride_h: 2 stride_w: 2\n pad_h: 0 pad_w: 0\n pad_up: 0 pad_down 0\n pad_left: 0 pad_right 0\n report_flag: 0\n bond_type: 1\n data_bit_mode: 0\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_max_pooling2d_2_MaxPool -> functional_1_conv2d_3_Conv2D;
functional_1_conv2d_3_Conv2D [shape=box, label="functional_1_conv2d_3_Conv2D\n id: 12  type: 0\n input size: 64*52*52\n output size: 128*52*52\n kernel_h: 3 kernel_w: 3\n stride_h: 1 stride_w: 1\n pad_h: 1 pad_w: 1\n pad_up: 1 pad_down 1\n pad_left: 1 pad_right 1\n report_flag: 0\n bond_type: 4\n data_bit_mode: 0\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_conv2d_3_Conv2D -> functional_1_batch_normalization_3_FusedBatchNormV3;
functional_1_batch_normalization_3_FusedBatchNormV3 [shape=box, label="functional_1_batch_normalization_3_FusedBatchNormV3\n id: 13  type: 24\n input size: 128*52*52\n output size: 128*52*52\n report_flag: 0\n bond_type: 1\n data_bit_mode: 2\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_batch_normalization_3_FusedBatchNormV3 -> functional_1_batch_normalization_3_FusedBatchNormV3_scale;
functional_1_batch_normalization_3_FusedBatchNormV3_scale [shape=box, label="functional_1_batch_normalization_3_FusedBatchNormV3_scale\n id: 14  type: 25\n input size: 128*52*52\n output size: 128*52*52\n report_flag: 0\n bond_type: 1\n data_bit_mode: 2\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_batch_normalization_3_FusedBatchNormV3_scale -> functional_1_max_pooling2d_3_MaxPool;
functional_1_max_pooling2d_3_MaxPool [shape=box, label="functional_1_max_pooling2d_3_MaxPool\n id: 15  type: 3\n input size: 128*52*52\n output size: 128*26*26\n kernel_h: 2 kernel_w: 2\n stride_h: 2 stride_w: 2\n pad_h: 0 pad_w: 0\n pad_up: 0 pad_down 0\n pad_left: 0 pad_right 0\n report_flag: 0\n bond_type: 1\n data_bit_mode: 0\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_max_pooling2d_3_MaxPool -> functional_1_conv2d_4_Conv2D;
functional_1_conv2d_4_Conv2D [shape=box, label="functional_1_conv2d_4_Conv2D\n id: 16  type: 0\n input size: 128*26*26\n output size: 256*26*26\n kernel_h: 3 kernel_w: 3\n stride_h: 1 stride_w: 1\n pad_h: 1 pad_w: 1\n pad_up: 1 pad_down 1\n pad_left: 1 pad_right 1\n report_flag: 0\n bond_type: 4\n data_bit_mode: 0\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_conv2d_4_Conv2D -> functional_1_batch_normalization_4_FusedBatchNormV3;
functional_1_batch_normalization_4_FusedBatchNormV3 [shape=box, label="functional_1_batch_normalization_4_FusedBatchNormV3\n id: 17  type: 24\n input size: 256*26*26\n output size: 256*26*26\n report_flag: 0\n bond_type: 1\n data_bit_mode: 2\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_batch_normalization_4_FusedBatchNormV3 -> functional_1_batch_normalization_4_FusedBatchNormV3_scale;
functional_1_batch_normalization_4_FusedBatchNormV3_scale [shape=box, label="functional_1_batch_normalization_4_FusedBatchNormV3_scale\n id: 18  type: 25\n input size: 256*26*26\n output size: 256*26*26\n report_flag: 0\n bond_type: 1\n data_bit_mode: 2\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_batch_normalization_4_FusedBatchNormV3_scale -> functional_1_conv2d_5_Conv2D;
functional_1_conv2d_5_Conv2D [shape=box, label="functional_1_conv2d_5_Conv2D\n id: 19  type: 0\n input size: 256*26*26\n output size: 3*26*26\n kernel_h: 1 kernel_w: 1\n stride_h: 1 stride_w: 1\n pad_h: 0 pad_w: 0\n pad_up: 0 pad_down 0\n pad_left: 0 pad_right 0\n report_flag: 0\n bond_type: 1\n data_bit_mode: 0\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
functional_1_conv2d_5_Conv2D -> functional_1_conv2d_5_Sigmoid;
functional_1_conv2d_5_Sigmoid [shape=box, label="functional_1_conv2d_5_Sigmoid\n id: 20  type: 8\n input size: 3*26*26\n output size: 3*26*26\n report_flag: -1\n bond_type: 1\n data_bit_mode: 2\n aligned_input_data_size: 0\n aligned_output_data_size: 0\n data_delta: 0"];
}
